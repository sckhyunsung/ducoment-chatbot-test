import os
import streamlit as st
from langchain.text_splitters import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain_community.document_loaders import PyPDFLoader, TextLoader, CSVLoader, UnstructuredWordDocumentLoader, UnstructuredExcelLoader, UnstructuredPowerPointLoader, UnstructuredHTMLLoader
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import Document
import tempfile
from langchain.agents import create_tool_calling_agent, AgentExecutor, Tool
import pandas as pd
import time
from bs4 import BeautifulSoup
import email
from email import policy

# í™˜ê²½ ì„¤ì •
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# í­ì£½ íš¨ê³¼ í•¨ìˆ˜
def show_celebration():
    st.balloons()
    time.sleep(0.5)
    st.snow()

# ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ ë¡œë“œ í•¨ìˆ˜
def load_documents(uploaded_files):
    all_documents = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_files = len(uploaded_files)
    
    for idx, uploaded_file in enumerate(uploaded_files):
        status_text.text(f"ğŸ“‚ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {uploaded_file.name} ({idx+1}/{total_files})")
        progress_bar.progress((idx + 1) / total_files)
        
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_extension}") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name
        
        try:
            # íŒŒì¼ í˜•ì‹ë³„ ë¡œë” ì„ íƒ
            if file_extension == 'pdf':
                loader = PyPDFLoader(tmp_file_path)
                documents = loader.load()
                
            elif file_extension == 'txt':
                loader = TextLoader(tmp_file_path, encoding='utf-8')
                documents = loader.load()
                for doc in documents:
                    doc.metadata['source'] = uploaded_file.name
                
            elif file_extension == 'csv':
                df = pd.read_csv(tmp_file_path)
                text = df.to_string()
                documents = [Document(page_content=text, metadata={"source": uploaded_file.name, "type": "CSV"})]
                
            elif file_extension in ['xlsx', 'xls']:
                excel_file = pd.ExcelFile(tmp_file_path)
                documents = []
                for sheet_name in excel_file.sheet_names:
                    df = pd.read_excel(tmp_file_path, sheet_name=sheet_name)
                    text = f"Sheet: {sheet_name}\n\n{df.to_string()}"
                    documents.append(Document(
                        page_content=text, 
                        metadata={
                            "source": uploaded_file.name, 
                            "sheet": sheet_name,
                            "type": "Excel"
                        }
                    ))
                    
            elif file_extension in ['docx', 'doc']:
                loader = UnstructuredWordDocumentLoader(tmp_file_path)
                documents = loader.load()
                for doc in documents:
                    doc.metadata['source'] = uploaded_file.name
                    doc.metadata['type'] = 'Word'
                
            elif file_extension in ['pptx', 'ppt']:
                loader = UnstructuredPowerPointLoader(tmp_file_path)
                documents = loader.load()
                for doc in documents:
                    doc.metadata['source'] = uploaded_file.name
                    doc.metadata['type'] = 'PowerPoint'
                
            elif file_extension in ['mhtml', 'mht']:
                # MHTML íŒŒì¼ ì²˜ë¦¬ (MIME ë©€í‹°íŒŒíŠ¸)
                try:
                    with open(tmp_file_path, 'rb') as f:
                        msg = email.message_from_binary_file(f, policy=policy.default)
                    
                    # HTML ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    text_parts = []
                    for part in msg.walk():
                        content_type = part.get_content_type()
                        if content_type in ['text/html', 'text/plain']:
                            try:
                                payload = part.get_payload(decode=True)
                                if payload:
                                    # ì¸ì½”ë”© ê°ì§€ ë° ë””ì½”ë”©
                                    charset = part.get_content_charset() or 'utf-8'
                                    try:
                                        text = payload.decode(charset, errors='ignore')
                                    except:
                                        text = payload.decode('utf-8', errors='ignore')
                                    
                                    # HTMLì¸ ê²½ìš° BeautifulSoupìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                    if content_type == 'text/html':
                                        soup = BeautifulSoup(text, 'html.parser')
                                        text = soup.get_text(separator='\n', strip=True)
                                    
                                    text_parts.append(text)
                            except Exception as e:
                                continue
                    
                    if text_parts:
                        combined_text = '\n\n'.join(text_parts)
                        documents = [Document(
                            page_content=combined_text,
                            metadata={
                                "source": uploaded_file.name,
                                "type": "MHTML"
                            }
                        )]
                    else:
                        st.warning(f"âš ï¸ MHTML íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {uploaded_file.name}")
                        continue
                        
                except Exception as e:
                    st.error(f"âŒ MHTML íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {uploaded_file.name} - {str(e)}")
                    continue
                
            else:
                st.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {uploaded_file.name}")
                continue
            
            all_documents.extend(documents)
            
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({uploaded_file.name}): {str(e)}")
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)
    
    progress_bar.empty()
    status_text.empty()
    
    return all_documents

# ë²¡í„°DB ìƒì„± (ì¶œì²˜ ì •ë³´ ê°•ì œ í¬í•¨)
def create_vectorstore(uploaded_files):
    status_container = st.empty()
    
    try:
        # 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë“œ
        status_container.info("ğŸ”„ **1ë‹¨ê³„**: ë¬¸ì„œ íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
        all_documents = load_documents(uploaded_files)
        
        if not all_documents:
            status_container.error("âŒ ë¬¸ì„œë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„í• 
        status_container.info(f"ğŸ”„ **2ë‹¨ê³„**: ë¬¸ì„œë¥¼ {len(all_documents)}ê°œì˜ ì„¹ì…˜ìœ¼ë¡œ ë¶„í• í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        text_splitters = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        split_docs = text_splitters.split_documents(all_documents)
        
        # 3ë‹¨ê³„: ë²¡í„° ì„ë² ë”©
        status_container.info(f"ğŸ”„ **3ë‹¨ê³„**: {len(split_docs)}ê°œì˜ ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n(OpenAI API í˜¸ì¶œ ì¤‘ - ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
        vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())
        retriever = vector.as_retriever(search_kwargs={"k": 5})
        
        # 4ë‹¨ê³„: ì™„ë£Œ
        status_container.success(f"âœ… **ì™„ë£Œ!** {len(uploaded_files)}ê°œ íŒŒì¼, {len(split_docs)}ê°œ ì²­í¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
        time.sleep(1)
        status_container.empty()
        
        # Custom ê²€ìƒ‰ í•¨ìˆ˜ - ì¶œì²˜ ì •ë³´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
        def search_documents(query: str) -> str:
            """ë¬¸ì„œ ê²€ìƒ‰ ë° ì¶œì²˜ ì •ë³´ í¬í•¨"""
            docs = retriever.get_relevant_documents(query)
            
            if not docs:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            result_text = "### ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©:\n\n"
            
            for idx, doc in enumerate(docs, 1):
                # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                source = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                page = doc.metadata.get('page', '')
                sheet = doc.metadata.get('sheet', '')
                doc_type = doc.metadata.get('type', '')
                
                # ì¶œì²˜ ì •ë³´ êµ¬ì„±
                location = ""
                if page != '':
                    location = f"{page}í˜ì´ì§€"
                elif sheet:
                    location = f"ì‹œíŠ¸: {sheet}"
                elif doc_type:
                    location = f"{doc_type} ë¬¸ì„œ"
                
                # ê²°ê³¼ í¬ë§·íŒ…
                result_text += f"**[ë¬¸ì„œ {idx}]**\n"
                result_text += f"- ğŸ“„ íŒŒì¼ëª…: {source}\n"
                if location:
                    result_text += f"- ğŸ“ ìœ„ì¹˜: {location}\n"
                result_text += f"- ğŸ“ ë‚´ìš©:\n{doc.page_content[:500]}...\n\n"
                result_text += "---\n\n"
            
            return result_text
        
        # Toolë¡œ ë³€í™˜
        from langchain.agents import Tool
        
        retriever_tool = Tool(
            name="document_search",
            func=search_documents,
            description=(
                "ì—…ë¡œë“œëœ ë¬¸ì„œ(PDF, Excel, Word, PowerPoint, Text, CSV)ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. "
                "ê²€ìƒ‰ ê²°ê³¼ëŠ” íŒŒì¼ëª…, í˜ì´ì§€/ì‹œíŠ¸ ì •ë³´ì™€ í•¨ê»˜ ë°˜í™˜ë©ë‹ˆë‹¤. "
                "ë°˜ë“œì‹œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”."
            )
        )
        
        return retriever_tool
        
    except Exception as e:
        status_container.error(f"âŒ ë²¡í„° DB ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

# ì„¸ì…˜ë³„ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
def get_session_history(session_ids):
    if session_ids not in st.session_state.session_history:
        st.session_state.session_history[session_ids] = ChatMessageHistory()
    return st.session_state.session_history[session_ids]

# ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
def print_messages():
    for msg in st.session_state["messages"]:
        with st.chat_message(msg['role']):
            st.markdown(msg['content'])

# ë©”ì¸ ì‹¤í–‰
def main():
    st.set_page_config(
        page_title="SCK ì±—ë´‡ Test ë„ìš°ë¯¸", 
        layout="wide", 
        page_icon="ğŸ¤–",
        initial_sidebar_state="expanded"
    )

    # í—¤ë” ì„¹ì…˜
    with st.container():
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if os.path.exists('./chatbot_logo.jpg'):
                st.image('./chatbot_logo.jpg', width=600)
            elif os.path.exists('chatbot_logo.jpg'):
                st.image('chatbot_logo.jpg', width=600)
        
        st.markdown('---')
        st.markdown("# SCK ì±—ë´‡ ê°œë°œ ë„ìš°ë¯¸")
        st.markdown("### Documentë¥¼ Uploadí•˜ì—¬ Testí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        st.markdown("**ë¬¸ì˜ ì‚¬í•­ì€ ê¸°ìˆ íŒ€ ì´í˜„ì„± ì„ ì„ì—ê²Œ ì§„í–‰í•´ ì£¼ì„¸ìš”.**")
        st.markdown("**Contact:** íŒ€ì¦ˆ or Mail ([hyunsung.lee@statschippac.com](mailto:hyunsung.lee@statschippac.com))")
        st.markdown('---')

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "session_history" not in st.session_state:
        st.session_state["session_history"] = {}
    if "vectorstore_ready" not in st.session_state:
        st.session_state["vectorstore_ready"] = False
    if "agent_executor" not in st.session_state:
        st.session_state["agent_executor"] = None
    if "is_processing" not in st.session_state:
        st.session_state["is_processing"] = False
    if "pending_question" not in st.session_state:
        st.session_state["pending_question"] = None

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        st.session_state["OPENAI_API"] = st.text_input(
            "OPENAI API í‚¤", 
            placeholder="sk-...", 
            type="password",
            help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        st.markdown('---')
        st.header("ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        # ì§€ì› íŒŒì¼ í˜•ì‹ ì•ˆë‚´
        with st.expander("ğŸ“‹ ì§€ì› íŒŒì¼ í˜•ì‹", expanded=False):
            st.markdown("""
            - ğŸ“• PDF (.pdf)
            - ğŸ“Š Excel (.xlsx, .xls)
            - ğŸ“˜ Word (.docx, .doc)
            - ğŸ¨ PowerPoint (.pptx, .ppt)
            - ğŸŒ MHTML (.mhtml, .mht)
            - ğŸ“„ Text (.txt)
            - ğŸ“‘ CSV (.csv)
            """)
        
        uploaded_files = st.file_uploader(
            "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", 
            accept_multiple_files=True, 
            type=['pdf', 'xlsx', 'xls', 'docx', 'doc', 'pptx', 'ppt', 'mhtml', 'mht', 'txt', 'csv'],
            key="file_uploader",
            help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        if uploaded_files:
            st.success(f"âœ… {len(uploaded_files)}ê°œì˜ íŒŒì¼ ì„ íƒë¨")
            
            # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
            with st.expander("ğŸ“‚ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡", expanded=True):
                total_size = 0
                for file in uploaded_files:
                    file_size = len(file.getvalue()) / 1024  # KB
                    total_size += file_size
                    file_icon = {
                        'pdf': 'ğŸ“•', 'xlsx': 'ğŸ“Š', 'xls': 'ğŸ“Š',
                        'docx': 'ğŸ“˜', 'doc': 'ğŸ“˜', 'pptx': 'ğŸ¨',
                        'ppt': 'ğŸ¨', 'mhtml': 'ğŸŒ', 'mht': 'ğŸŒ',
                        'txt': 'ğŸ“„', 'csv': 'ğŸ“‘'
                    }.get(file.name.split('.')[-1].lower(), 'ğŸ“„')
                    
                    st.markdown(f"{file_icon} **{file.name}**")
                    st.caption(f"í¬ê¸°: {file_size:.1f} KB")
                
                st.markdown(f"**ì´ ìš©ëŸ‰**: {total_size:.1f} KB")
        
        # í†µê³„ ì •ë³´
        if st.session_state["vectorstore_ready"]:
            st.markdown('---')
            st.header("ğŸ“Š ì„¸ì…˜ ì •ë³´")
            st.metric("ëŒ€í™” ìˆ˜", len(st.session_state["messages"]) // 2)
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™”"):
                st.session_state["messages"] = []
                st.session_state["session_history"] = {}
                st.rerun()

    # ë©”ì¸ ì˜ì—­
    if not st.session_state["OPENAI_API"]:
        st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.info("ğŸ’¡ API í‚¤ëŠ” ê¸°ìˆ íŒ€ ì´í˜„ì„± ì„ ì„ì—ê²Œ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤.")
        return
    
    if not uploaded_files:
        st.info("ğŸ“„ ì‚¬ì´ë“œë°”ì—ì„œ ë¬¸ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.markdown("""
        ### ğŸ’¡ ì‚¬ìš© ë°©ë²•
        1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ ì…ë ¥
        2. ë¶„ì„í•˜ê³  ì‹¶ì€ ë¬¸ì„œ íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
        3. ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ í›„ ì§ˆë¬¸ ì…ë ¥
        4. AIê°€ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ì œê³µ
        
        ### âš ï¸ ì£¼ì˜ì‚¬í•­
        - ì—…ë¡œë“œëœ ë¬¸ì„œëŠ” OpenAI ì„œë²„ë¡œ ì „ì†¡ë©ë‹ˆë‹¤
        - ê¸°ë°€ ë¬¸ì„œëŠ” ì—…ë¡œë“œí•˜ì§€ ë§ˆì„¸ìš”
        - ì„¸ì…˜ ì¢…ë£Œ ì‹œ ëª¨ë“  ë°ì´í„°ê°€ ì‚­ì œë©ë‹ˆë‹¤
        """)
        return

    # ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ)
    os.environ['OPENAI_API_KEY'] = st.session_state["OPENAI_API"]
    
    current_file_names = [f.name for f in uploaded_files]
    
    if "previous_files" not in st.session_state:
        st.session_state["previous_files"] = []
    
    # íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if current_file_names != st.session_state["previous_files"]:
        st.session_state["vectorstore_ready"] = False
        st.session_state["previous_files"] = current_file_names
        st.session_state["messages"] = []
        st.session_state["session_history"] = {}
    
    if not st.session_state["vectorstore_ready"]:
        with st.container():
            st.info("ğŸ”„ ë¬¸ì„œ ì—…ë¡œë“œë¥¼ ê°ì§€í–ˆìŠµë‹ˆë‹¤. ë²¡í„° ì„ë² ë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            doc_search = create_vectorstore(uploaded_files)
            
            if doc_search is None:
                st.error("âŒ ë¬¸ì„œ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return
            
            # LLM ë° Agent ì„¤ì •
            tools = [doc_search]
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

            prompt = ChatPromptTemplate.from_messages([
                ("system",
                "ë‹¹ì‹ ì€ 'SCK ì±—ë´‡ Test ë„ìš°ë¯¸'ì…ë‹ˆë‹¤.\n\n"
                
                "# ì¤‘ìš”: ë„êµ¬ ì‚¬ìš© í•„ìˆ˜\n"
                "ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ ë°˜ë“œì‹œ ë¨¼ì € document_search ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤.\n"
                "ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‹µë³€í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n\n"
                
                "# ì‘ë™ ìˆœì„œ\n"
                "1. ì§ˆë¬¸ ë°›ìŒ\n"
                "2. document_search ë„êµ¬ ì‹¤í–‰ (í•„ìˆ˜)\n"
                "3. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ì‘ì„±\n"
                "4. ì¶œì²˜ ì •ë³´ í¬í•¨\n\n"
                
                "# ë‹µë³€ í˜•ì‹\n"
                "## ìš”ì•½\n"
                "í•µì‹¬ ë‚´ìš© ê°„ë‹¨íˆ ì„¤ëª…\n\n"
                
                "## ìƒì„¸ ë‚´ìš©\n"
                "- ë°ì´í„°ëŠ” í‘œë¡œ ì •ë¦¬\n"
                "- ìˆ˜ì¹˜ëŠ” ì •í™•í•˜ê²Œ (ë‹¨ìœ„ í¬í•¨)\n"
                "- ë‚ ì§œ/ì‹œê°„ì€ ì›ë³¸ í˜•ì‹ ìœ ì§€\n\n"
                
                "## ì°¸ê³  ë¬¸ì„œ\n"
                "íŒŒì¼ëª…ê³¼ ìœ„ì¹˜ ì •ë³´\n\n"
                
                "# ê·œì¹™\n"
                "- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡ ê¸ˆì§€\n"
                "- í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€\n"
                "- ë°˜ë“œì‹œ ë„êµ¬ë¥¼ ë¨¼ì € ì‚¬ìš©"),
                ("placeholder", "{chat_history}"),
                ("human", "{input}"),
                ("placeholder", "{agent_scratchpad}"),
            ])

            agent = create_tool_calling_agent(llm, tools, prompt)
            agent_executor = AgentExecutor(
                agent=agent, 
                tools=tools, 
                verbose=True,
                handle_parsing_errors=True,
                max_iterations=15,
                early_stopping_method="force",
                return_intermediate_steps=True
            )
            
            st.session_state["agent_executor"] = agent_executor
            st.session_state["vectorstore_ready"] = True
            
            # í­ì£½ íš¨ê³¼
            show_celebration()
            st.success("ğŸ‰ ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            time.sleep(1)
            st.rerun()

    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    if st.session_state["vectorstore_ready"]:
        # ì§ˆë¬¸ ì…ë ¥ì°½ - ìµœìƒë‹¨ì— ë°°ì¹˜í•˜ì—¬ ìš°ì„  ë Œë”ë§
        user_input = st.chat_input(
            'ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...',
            disabled=st.session_state["is_processing"],
            key="chat_input"
        )
        
        # ìƒˆ ì§ˆë¬¸ ì…ë ¥ ì‹œ - ì¦‰ì‹œ ì²˜ë¦¬
        if user_input and not st.session_state["is_processing"]:
            st.session_state["is_processing"] = True
            st.session_state["pending_question"] = user_input
            st.rerun()
        
        # ì²˜ë¦¬ ì¤‘ ìƒíƒœ í‘œì‹œ
        if st.session_state["is_processing"]:
            st.warning("â³ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        
        # ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
        print_messages()
        
        # ëŒ€ê¸° ì¤‘ì¸ ì§ˆë¬¸ ì²˜ë¦¬
        if st.session_state["pending_question"]:
            question = st.session_state["pending_question"]
            st.session_state["pending_question"] = None
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
            st.session_state["messages"].append({"role": "user", "content": question})
            with st.chat_message("user"):
                st.markdown(question)
            
            # AI ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                status_placeholder = st.empty()
                status_placeholder.info("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
                
                try:
                    session_id = "default_session"
                    session_history = get_session_history(session_id)
                    
                    # Agent ì‹¤í–‰
                    status_placeholder.info("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...")
                    result = st.session_state["agent_executor"].invoke({"input": question})
                    response = result['output']
                    
                    status_placeholder.empty()
                    st.markdown(response)
                    
                    # ë©”ì‹œì§€ ì €ì¥
                    st.session_state["messages"].append({"role": "assistant", "content": response})
                    session_history.add_message({"role": "user", "content": question})
                    session_history.add_message({"role": "assistant", "content": response})
                    
                except Exception as e:
                    status_placeholder.empty()
                    error_msg = f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n\n```\n{str(e)}\n```\n\në‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                    st.error(error_msg)
                    st.session_state["messages"].append({"role": "assistant", "content": error_msg})
                
                finally:
                    # ì²˜ë¦¬ ì™„ë£Œ
                    st.session_state["is_processing"] = False
                    time.sleep(0.3)  # ì§§ì€ ë”œë ˆì´ í›„ ë¦¬ë Œë”ë§
                    st.rerun()

if __name__ == "__main__":
    main()